import os, pandas, dendropy
from hmm_profile reader, writer
from Bio.SeqIO import parse
from Bio import AlignIO
from Bio.Align import MultipleSeqAlignment

FILES1 = glob_wildcards( 'data/hmms-enabled/{hmm}.hmm' )
FILES2 = glob_wildcards( 'data/genomes-enabled/{fasta}.fna' )

# extract the {hmm} values into a list
HMMS    = FILES1.hmm
GENOMES = FILES2.fasta

# post-trimming aligned fraction threshold
AFT = 0.75

# borrowed from CheckV
def parse_hmmsearch( path ) :
  with open(path) as f:
    names = [ "qname", "qacc", "tname", "tacc",   "eval", 
              "score", "bias", "beval", "bscore", "bbias" ]
    formats = [ str,   str,   str,   str,   float, 
                float, float, float, float, float ]
    for line in f:
      if not line.startswith("#") :
        values = line.split()
        yield dict( [ ( names[i], formats[i](values[i]) ) 
                      for i in range(10) ] )

rule all :
  input :
    expand( 'trees/by_taxa/{hmm}.nwk', hmm=HMMS ),
    'statistics/summary.txt'

rule clean :
  shell :
    'rm -rf proteins hmm_hits prealignments\
        alignments trimmed_alignments\
        filtered_trimmed_alignments\
        trees statistics logs'

rule statistics :
  input :
    hmms       = expand( 'data/hmms-enabled/{hmm}.hmm', hmm=HMMS ),
    genomes    = expand( 'data/genomes-enabled/{fasta}.fna', fasta=GENOMES ),
    proteins   = expand( 'proteins/{fasta}_genes.faa', fasta=GENOMES ),
    hits       = expand( 'hmm_hits/{fasta}_{hmm}_prot_tbl.txt', hmm=HMMS, fasta=GENOMES ),
    alignments = expand( 'trimmed_alignments/{hmm}.msa.faa', hmm=HMMS ),
    trees      = expand( 'trees/by_taxa/{hmm}.nwk', hmm=HMMS )
  output :
    'statistics/summary.txt'
  log :
    notebook='logs/notebooks/statistics.ipynb',
  notebook :
    'notebooks/statistics.ipynb'

rule prodigal :
  input :
    fna='data/genomes-enabled/{fasta}.fna', 
  output :
    faa='proteins/{fasta}_genes.faa',
    #fna='proteins/{fasta}_genes.fna',
    #gff='proteins/{fasta}_genes.gff',
  log :
    'logs/prodigal/{fasta}.log',
  params :
    extra='',  # Additional arguments
  wrapper :
    'file://wrappers/prodigal-gv'

rule hmmdb :
  input :
    hmms = expand( 'data/hmms-enabled/{hmm}.hmm', hmm=HMMS )
  output :
    db   = 'hmmdb/models.hmm'
  log :
    'logs/hmmdb/hmmdb.log'
  run :
    profiles = []
    for hmmfile in hmms :
      hmm = reader.read_single( open( hmmfile ) )
      assert hmmfile == hmm.metadata.model_name
      profiles.append( hmm ) 
    writer.save_many_to_file( hmms=profiles, outpath=output.db )

rule hmmer :
  input :
    fasta   = 'proteins/{fasta}_genes.faa',
    profile = 'hmmdb/models.hmm'
  log :
    'logs/hmmer/{fasta}.log',
  output :
    tblout         = 'hmm_hits/{fasta}_prot_tbl.txt',
    #domtblout      = 'hmm_hits/{fasta}_{hmm}_prot_dom_tbl.txt',
    #alignment_hits = 'hmm_hits/{fasta}_{hmm}_alg_hits.txt',
    #outfile        = 'hmm_hits/{fasta}_{hmm}_prot.txt'
  wrapper :
    'file://wrappers/hmmer/hmmsearch'

rule scoring :
  input :
    # for each HMM...
    hits = expand( 'hmm_hits/{fasta}_{{hmm}}_prot_tbl.txt',
                   fasta=GENOMES ),
    # ...score orthologs for each genome
    faa  = expand( 'proteins/{fasta}_genes.faa',
                   fasta=GENOMES )
  output :
    prealign = 'prealignments/{hmm}.faa'
  run :
    nohits = 0
    for tblout,faa in zip( input.hits, input.faa ) :
      hits = pandas.DataFrame( [ h for h in parse_hmmsearch( tblout ) ] )
      if hits.shape[0] == 0 :
        nohits += 1
        continue
      top_hit = hits.sort_values( 'bscore', ascending=False ).iloc[0]
      with open( output.prealign, 'a' ) as f :
        for rec in parse( open( faa ), 'fasta' ) :
          if rec.id == top_hit['qname'] :
            if rec.seq[-1] == '*' : # don't include the stop codon
              f.write( rec[:-1].format( 'fasta' ) )
            else :
              f.write( rec.format( 'fasta' ) )
            break
    if nohits == len( input.hits ) :
      print( 'writing empty file for {a}...'.format( a=output.prealign ) )
      with open( output.prealign, 'w' ) as f :
        f.write( '' )

rule clustalo :
  input :
    'prealignments/{hmm}.faa'
  output :
    'alignments/{hmm}.msa.faa'
  params:
    extra=''
  log :
    'logs/clustalo/{hmm}.log'
  threads : 8
  wrapper :
    'file://wrappers/clustalo'

rule trimal :
  input :
    'alignments/{hmm}.msa.faa'
  output :
    'trimmed_alignments/{hmm}.msa.faa'
  log :
    'logs/trimal/{hmm}.log'
  params :
    extra='-automated1'
  wrapper :
    'file://wrappers/trimal'

rule filter_alignments :
  input :
    'trimmed_alignments/{hmm}.msa.faa'
  output :
    'filtered_trimmed_alignments/{hmm}.msa.faa'
  log :
    'logs/filter_alignments/{hmm}.log'
  run :
    if open( input[0] ).read().count( '>' ) < 3 :
      with open( log[0], 'w' ) as f :
        f.write( 'no records.' )
      with open( output[0], 'w' ) as f :
        f.write( '' )
    else :
      A = AlignIO.read( input[0], 'fasta' )
      L = A.get_alignment_length()
      B = MultipleSeqAlignment( [ s for s in A if len(s.seq.ungap())/L > AFT ] )
      with open( log[0], 'w' ) as f :
        f.write( 'aligned fraction threshold : {n}\n'.format( n=AFT ) )
        f.write( 'alignment length           : {n}\n'.format( n=L ) )
        f.write( 'input alignment sequences  : {n}\n'.format( n=len(A) ) )
        f.write( 'output alignment sequences : {n}\n'.format( n=len(B) ) )
      with open( output[0], 'w' ) as f :
        if len(B) >= 3 :
          AlignIO.write( B, f, 'fasta' )
        else :
          f.write( '' )

rule fasttree :
  input :
    alignment='filtered_trimmed_alignments/{hmm}.msa.faa'
  output :
    tree='trees/by_gene/{hmm}.nwk'
  log :
    'logs/fasttree/{hmm}.log'
  params :
    extra=''
  wrapper :
    'file://wrappers/fasttree'

rule taxatrees :
  input :
    'trees/by_gene/{hmm}.nwk',
  output :
    'trees/by_taxa/{hmm}.nwk',
  log :
    'logs/gene-taxa/{hmm}_mapping.txt',
  run :
    with open( log[0], 'w' ) as f :
      if not os.path.getsize( input[0] ) == 0 :
        T = dendropy.Tree.get( path=input[0],
                               schema='newick',
                               preserve_underscores=True )
        for leaf in T.leaf_nodes() :
          taxon = leaf.taxon.label.rsplit('|', 1)[0].rsplit('_', 2)[0]
          f.write( '{a}\t{b}\n'.format( a=leaf.taxon.label, b=taxon ) )
          leaf.taxon.label = taxon
        T.write( path=output[0],
                 schema='newick' )
      else :
        open( output[0], 'w' ).close()
