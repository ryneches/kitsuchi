import os, pandas, dendropy
from Bio.SeqIO import parse

FILES1 = glob_wildcards( 'data/hmms-enabled/{hmm}.hmm' )
FILES2 = glob_wildcards( 'data/genomes-enabled/{fasta}.fna' )

# extract the {hmm} values into a list
HMMS    = FILES1.hmm
GENOMES = FILES2.fasta

# borrowed from CheckV
def parse_hmmsearch( path ) :
  with open(path) as f:
    names = [ "qname", "qacc", "tname", "tacc",   "eval", 
              "score", "bias", "beval", "bscore", "bbias" ]
    formats = [ str,   str,   str,   str,   float, 
                float, float, float, float, float ]
    for line in f:
      if not line.startswith("#") :
        values = line.split()
        yield dict( [ ( names[i], formats[i](values[i]) ) 
                      for i in range(10) ] )

rule all :
  input :
    expand( 'trees/by_taxa/{hmm}.nwk', hmm=HMMS ),
    'statistics/summary.txt'

rule clean :
  shell :
    'rm -rf proteins hmm_hits prealignments alignments trees statistics logs'

rule statistics :
  input :
    hmms       = expand( 'data/hmms-enabled/{hmm}.hmm', hmm=HMMS ),
    genomes    = expand( 'data/genomes-enabled/{fasta}.fna', fasta=GENOMES ),
    proteins   = expand( 'proteins/{fasta}_genes.faa', fasta=GENOMES ),
    hits       = expand( 'hmm_hits/{fasta}_{hmm}_prot_tbl.txt', hmm=HMMS, fasta=GENOMES ),
    alignments = expand( 'alignments/{hmm}.msa.faa', hmm=HMMS ),
    trees      = expand( 'trees/by_taxa/{hmm}.nwk', hmm=HMMS )
  output :
    'statistics/summary.txt'
  log :
    notebook='logs/notebooks/statistics.ipynb',
  notebook :
    'notebooks/statistics.ipynb'

rule prodigal :
  input :
    fna='data/genomes-enabled/{fasta}.fna', 
  output :
    faa='proteins/{fasta}_genes.faa',
    #fna='proteins/{fasta}_genes.fna',
    #gff='proteins/{fasta}_genes.gff',
  log :
    'logs/prodigal/{fasta}.log',
  params :
    extra='',  # Additional arguments
  wrapper :
    'file://wrappers/prodigal-gv'

rule hmmer :
  input :
    fasta   = 'proteins/{fasta}_genes.faa',
    profile = 'data/hmms-enabled/{hmm}.hmm'
  log :
    'logs/hmmer/{fasta}_{hmm}.log',
  output :
    tblout         = 'hmm_hits/{fasta}_{hmm}_prot_tbl.txt',
    #domtblout      = 'hmm_hits/{fasta}_{hmm}_prot_dom_tbl.txt',
    #alignment_hits = 'hmm_hits/{fasta}_{hmm}_alg_hits.txt',
    #outfile        = 'hmm_hits/{fasta}_{hmm}_prot.txt'
  wrapper :
    'file://wrappers/hmmer/hmmsearch'

rule scoring :
  input :
    # for each HMM...
    hits = expand( 'hmm_hits/{fasta}_{{hmm}}_prot_tbl.txt',
                   fasta=GENOMES ),
    # ...score orthologs for each genome
    faa  = expand( 'proteins/{fasta}_genes.faa',
                   fasta=GENOMES )
  output :
    prealign = 'prealignments/{hmm}.faa'
  run :
    nohits = 0
    for tblout,faa in zip( input.hits, input.faa ) :
      hits = pandas.DataFrame( [ h for h in parse_hmmsearch( tblout ) ] )
      if hits.shape[0] == 0 :
        nohits += 1
        continue
      top_hit = hits.sort_values( 'bscore', ascending=False ).iloc[0]
      with open( output.prealign, 'a' ) as f :
        for rec in parse( open( faa ), 'fasta' ) :
          if rec.id == top_hit['qname'] : 
            f.write( rec.format( 'fasta' ) )
            break
    if nohits == len( input.hits ) :
      print( 'writing empty file for {a}...'.format( a=output.prealign ) )
      with open( output.prealign, 'w' ) as f :
        f.write( '' )

rule clustalo :
  input :
    'prealignments/{hmm}.faa'
  output :
    'alignments/{hmm}.msa.faa'
  params:
    extra=''
  log :
    'logs/clustalo/{hmm}.log'
  threads : 8
  wrapper :
    'file://wrappers/clustalo'

rule fasttree :
  input :
    alignment='alignments/{hmm}.msa.faa'
  output :
    tree='trees/by_gene/{hmm}.nwk'
  log :
    'logs/fasttree/{hmm}.log'
  params :
    extra=''
  wrapper :
    'file://wrappers/fasttree'

rule taxatrees :
  input :
    'trees/by_gene/{hmm}.nwk',
  output :
    'trees/by_taxa/{hmm}.nwk',
  log :
    'logs/gene-taxa/{hmm}_mapping.txt',
  run :
    with open( log[0], 'w' ) as f :
      if not os.path.getsize( input[0] ) == 0 :
        T = dendropy.Tree.get( path=input[0],
                               schema='newick',
                               preserve_underscores=True )
        for leaf in T.leaf_nodes() :
          taxon = leaf.taxon.label.rsplit('|', 1)[0].rsplit('_', 2)[0]
          f.write( '{a}\t{b}\n'.format( a=leaf.taxon.label, b=taxon ) )
          leaf.taxon.label = taxon
        T.write( path=output[0],
                 schema='newick' )
      else :
        open( output[0], 'w' ).close()
