import os, pandas, dendropy
from pathlib import Path
from copy import deepcopy
from hmm_profile import reader, writer
from Bio.SeqIO import parse
from Bio import AlignIO
from Bio.Align import MultipleSeqAlignment

FILES1 = glob_wildcards( 'data/hmms-enabled/{hmm}.hmm' )
FILES2 = glob_wildcards( 'data/genomes-enabled/{fasta}.fna' )

# extract the {hmm} values into a list
HMMS    = FILES1.hmm
GENOMES = FILES2.fasta

# e-value threshold for HMM search
EVALUE = 10e-3

# post-trimming aligned fraction threshold
AFT = 0.75

# threads to use when invoking multithreaded applications
THREADS=2

# borrowed from CheckV
def parse_hmmsearch( path ) :
  with open(path) as f:
    names = [ 'tname', 'qacc', 'qname', 'tacc',   'eval', 
              'score', 'bias', 'beval', 'bscore', 'bbias' ]
    formats = [ str,   str,   str,   str,   float, 
                float, float, float, float, float ]
    for line in f:
      if not line.startswith( '#' ) :
        values = line.split()
        yield dict( [ ( names[i], formats[i](values[i]) ) 
                      for i in range(10) ] )

rule all :
  input :
    expand( 'trees/by_taxa/{hmm}.nwk', hmm=HMMS ),
    'statistics/summary.txt'

rule clean :
  shell :
    'rm -rf proteins hmm_hits hmmdb \
        prealignments\ alignments \
        trimmed_alignments\
        filtered_trimmed_alignments\
        trees statistics logs'

rule statistics :
  input :
    hmms       = expand( 'data/hmms-enabled/{hmm}.hmm', hmm=HMMS ),
    genomes    = expand( 'data/genomes-enabled/{fasta}.fna', fasta=GENOMES ),
    proteins   = expand( 'proteins/{fasta}_genes.faa', fasta=GENOMES ),
    hits       = expand( 'hmm_hits/{fasta}_prot_tbl.txt', hmm=HMMS, fasta=GENOMES ),
    alignments = expand( 'trimmed_alignments/{hmm}.msa.faa', hmm=HMMS ),
    trees      = expand( 'trees/by_taxa/{hmm}.nwk', hmm=HMMS )
  output :
    'statistics/summary.txt'
  log :
    notebook='logs/notebooks/statistics.ipynb',
  notebook :
    'notebooks/statistics.ipynb'

rule prodigal :
  input :
    fna='data/genomes-enabled/{fasta}.fna', 
  output :
    faa='proteins/{fasta}_genes.faa',
    #fna='proteins/{fasta}_genes.fna',
    #gff='proteins/{fasta}_genes.gff',
  log :
    'logs/prodigal/{fasta}.log',
  params :
    extra='',  # Additional arguments
  wrapper :
    'file://wrappers/prodigal-gv'

rule hmmdb :
  input :
    hmms = expand( 'data/hmms-enabled/{hmm}.hmm', hmm=HMMS )
  output :
    db   = 'hmmdb/models.hmm'
  log :
    'logs/hmmdb/hmmdb.log'
  run :
    profiles = []
    for hmmfile in input.hmms :
      hmm = reader.read_single( open( hmmfile ) )
      if Path(hmmfile).stem != hmm.metadata.model_name :
        raise Exception( 'file name ({hmmfile}) must match model name ({modelname}).'.format(
                          hmmfile=hmmfile, modelname=hmm.metadata.model_name ) )
      profiles.append( hmm ) 
    writer.save_many_to_file( hmms=profiles, output=output.db )

rule hmmer :
  input :
    fasta   = 'proteins/{fasta}_genes.faa',
    profile = 'hmmdb/models.hmm'
  log :
    'logs/hmmer/{fasta}.log',
  output :
    tblout         = 'hmm_hits/{fasta}_prot_tbl.txt',
    #domtblout      = 'hmm_hits/{fasta}_{hmm}_prot_dom_tbl.txt',
    #alignment_hits = 'hmm_hits/{fasta}_{hmm}_alg_hits.txt',
    #outfile        = 'hmm_hits/{fasta}_{hmm}_prot.txt'
  wrapper :
    'file://wrappers/hmmer/hmmsearch'

rule scoring :
  input :
    # for each HMM...
    hits    = expand( 'hmm_hits/{fasta}_prot_tbl.txt', fasta=GENOMES ),
    # ...score orthologs for each genome
    faa     = expand( 'proteins/{fasta}_genes.faa', fasta=GENOMES ),
    profile = 'hmmdb/models.hmm'
  output :
    prealign = expand( 'prealignments/{hmm}.faa', hmm=HMMS )
  log :
    'logs/scoring/scoring.log'
  run :
    with open( log[0], 'w' ) as LOG :
      prealignments = { Path(p).stem : { 'prealign' : p,
                                         'hits'     : [] } for p in output.prealign }
      # use trusted cutoffs if provided
      trusted_cutoffs = { m.metadata.model_name : m.metadata.trusted_cutoff
                          for m in reader.read_all( open( input.profile ) ) }
      LOG.write( 'parsed {n} hmms, found {m} trusted cutoffs\n'.format( 
                    n=str(len(trusted_cutoffs)),
                    m=str(sum( [ bool(v) for v in trusted_cutoffs.values() ] ) ) ) )
      for tblout,faa in zip( input.hits, input.faa ) :
        hits = pandas.DataFrame( [ h for h in parse_hmmsearch( tblout ) ] )
        seqs = { seq.id : seq for seq in parse( open( faa ), 'fasta' ) }
        genome = Path(faa).stem.rsplit('_',1)[0]
        LOG.write( '{genome} : found {n} hits for {m} proteins\n'.format(
                      genome=genome,
                      n=str(len(hits)),
                      m=str(len(seqs)) ) )
        if len( hits ) == 0 : continue
        for hmm in set( hits['qname'] ) :
          if trusted_cutoffs[ hmm ] :
            top_hits = hits[ ( hits['qname'] == hmm ) &
                             ( hits['score'] >= trusted_cutoff[hmm] ) ].sort_values( 
                                'score', axis=0, ascending=False )
          else :
            top_hits = hits[ ( hits['qname'] == hmm ) &
                             ( hits['eval']  <= EVALUE ) ].sort_values( 
                                'score', axis=0, ascending=False )
          if len( top_hits ) == 0 : continue
          with open( prealignments[ hmm ]['prealign'], 'a' ) as f :
            for i,(n,row) in enumerate( top_hits.iterrows() ) :
              LOG.write( '   {hmm} {n} : {tname}\n'.format( hmm=hmm, n=str(i), tname=row['tname'] ) )
              seq = deepcopy( seqs[ row['tname'] ] )
              if seq.seq[-1] == '*' : seq = seq[:-1]
              seq.id = seq.id + '_p' + str(i)
              prealignments[hmm]['hits'].append( seq.id )
              f.write( seq.format( 'fasta' ) )
      for k,p in prealignments.items() :
        LOG.write( '{hmm} : \n'.format( hmm=k ) )
        for hit in p['hits'] :
          LOG.write( '    {hit}\n'.format( hit=hit ) )
        if len( p['hits'] ) == 0 :
          LOG.write( '    NONE\n' )
          with open( p['prealign'], 'w' ) as f :
            f.write( '' )

rule clustalo :
  input :
    'prealignments/{hmm}.faa'
  output :
    'alignments/{hmm}.msa.faa'
  params:
    extra=''
  log :
    'logs/clustalo/{hmm}.log'
  threads : THREADS
  wrapper :
    'file://wrappers/clustalo'

rule trimal :
  input :
    'alignments/{hmm}.msa.faa'
  output :
    'trimmed_alignments/{hmm}.msa.faa'
  log :
    'logs/trimal/{hmm}.log'
  params :
    extra='-automated1'
  wrapper :
    'file://wrappers/trimal'

rule filter_alignments :
  input :
    'trimmed_alignments/{hmm}.msa.faa'
  output :
    'filtered_trimmed_alignments/{hmm}.msa.faa'
  log :
    'logs/filter_alignments/{hmm}.log'
  run :
    if open( input[0] ).read().count( '>' ) < 3 :
      with open( log[0], 'w' ) as f :
        f.write( 'no records.' )
      with open( output[0], 'w' ) as f :
        f.write( '' )
    else :
      A = AlignIO.read( input[0], 'fasta' )
      L = A.get_alignment_length()
      B = MultipleSeqAlignment( [ s for s in A if len(s.seq.ungap())/L > AFT ] )
      with open( log[0], 'w' ) as f :
        f.write( 'aligned fraction threshold : {n}\n'.format( n=AFT ) )
        f.write( 'alignment length           : {n}\n'.format( n=L ) )
        f.write( 'input alignment sequences  : {n}\n'.format( n=len(A) ) )
        f.write( 'output alignment sequences : {n}\n'.format( n=len(B) ) )
      with open( output[0], 'w' ) as f :
        if len(B) >= 3 :
          AlignIO.write( B, f, 'fasta' )
        else :
          f.write( '' )

rule fasttree :
  input :
    alignment='filtered_trimmed_alignments/{hmm}.msa.faa'
  output :
    tree='trees/by_gene/{hmm}.nwk'
  log :
    'logs/fasttree/{hmm}.log'
  params :
    extra=''
  wrapper :
    'file://wrappers/fasttree'

rule taxatrees :
  input :
    'trees/by_gene/{hmm}.nwk',
  output :
    'trees/by_taxa/{hmm}.nwk',
  log :
    'logs/gene-taxa/{hmm}_mapping.txt',
  run :
    with open( log[0], 'w' ) as f :
      if not os.path.getsize( input[0] ) == 0 :
        T = dendropy.Tree.get( path=input[0],
                               schema='newick',
                               preserve_underscores=True )
        for leaf in T.leaf_nodes() :
          taxon = leaf.taxon.label.rsplit('|', 1)[0].rsplit('_', 2)[0]
          f.write( '{a}\t{b}\n'.format( a=leaf.taxon.label, b=taxon ) )
          leaf.taxon.label = taxon
        T.write( path=output[0],
                 schema='newick' )
      else :
        open( output[0], 'w' ).close()
